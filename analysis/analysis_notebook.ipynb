{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "import umap\n",
    "\n",
    "sys.path.append('../ml_pipeline')\n",
    "import label_converter\n",
    "\n",
    "# import functions instead of having them in here to keep the notebook *much* shorter\n",
    "sys.path.append('functions')\n",
    "import confusion_matrix\n",
    "import roc_curve\n",
    "import image_excerpt\n",
    "import beeswarm\n",
    "import image_bytestream\n",
    "import bokeh_wrapper\n",
    "import umap_embedding\n",
    "import entropy_plot\n",
    "import sc_occlusion\n",
    "import load_data\n",
    "import prediction_barplot\n",
    "\n",
    "\n",
    "fontsize=12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define analysis.\n",
    "To analyze cross-validation, enter the path of the first fold folder. Each folder for one fold should contain ```_x``` at the end of the name, allowing the algorithm to identify the fold. Example:\n",
    "```\n",
    "result_folder\n",
    "    abmil_0\n",
    "    abmil_1\n",
    "    abmil_2\n",
    "    ...\n",
    "```\n",
    "\n",
    "The proper value to set for ```result_folder_path``` would be: ```result_folder/abmil_0``` and the notebook will recognize cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_export_path = 'output'\n",
    "result_folder_path= r'C:\\Science\\TCIA Data\\output\\out_f_0'\n",
    "dataset_folder = r'C:\\Science\\TCIA Data\\TCIA_data_prepared'\n",
    "feature_prefix = 'fnl34_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify cross valdation & load all the data\n",
    "This process loads all feature vectors and prepares all the data for further display, so it will take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify all folders with cross validation\n",
    "folders_cv_truncated = os.path.basename(result_folder_path)[:-1]\n",
    "folders_cv_available = [f for f in os.listdir('{}/..'.format(result_folder_path)) if folders_cv_truncated == f[:-1]]\n",
    "print(\"Found {} folder{}, loading data.\".format(len(folders_cv_available), 's' if len(folders_cv_available) > 1 else ''))\n",
    "\n",
    "data = load_data.load_dataframes(folders_cv_available, \n",
    "                    os.path.dirname(result_folder_path),\n",
    "                    feature_prefix,\n",
    "                    dataset_folder)\n",
    "\n",
    "lbl_conv_obj, patient_df, sc_df = data\n",
    "print(\"Classification labels: {}\".format(list(lbl_conv_obj.df.true_lbl)))\n",
    "print(\"Annotated patients: \", list(sc_df.loc[~sc_df['mll_annotation'].isna()].index.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate some patient data: total images, images per patient mean + sd\n",
    "print(\"Total images: \", len(sc_df))\n",
    "print(\"Images per patient (mean): \", sc_df.index.value_counts().mean())\n",
    "print(\"Images per patient (std): \", sc_df.index.value_counts().std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: classification performance\n",
    "\n",
    "### Confusion matrix\n",
    "Analyze overall classification performance in 5-fold cross-vaildation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reorder=['PML_RARA',\n",
    "        'NPM1',\n",
    "        'CBFB_MYH11',\n",
    "        'RUNX1_RUNX1T1',\n",
    "        'control']\n",
    "\n",
    "confusion_data = load_data.extract_confusion_matrix(patient_df, lbl_conv_obj)\n",
    "confusion_matrix.show_pred_mtrx(pred_mtrx = confusion_data,\n",
    "                                class_conversion = lbl_conv_obj.df,\n",
    "                               reorder=reorder, fig_size=(8.1,4.5), sc_df=sc_df,\n",
    "                               path_save=os.path.join(fig_export_path, 'confusion_matrix.svg'))\n",
    "\n",
    "print(\"Overall accuracy: {}\".format(confusion_matrix.get_accuracy(confusion_data)))\n",
    "confusion_matrix.get_classwise_values_as_df(confusion_data, lbl_conv_obj).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold-wise performance\n",
    "full_confusion_data = {}\n",
    "for fold in sorted(patient_df.fold.unique()):\n",
    "    patient_df_filtered = patient_df.loc[patient_df['fold'] == fold]\n",
    "    confusion_data = load_data.extract_confusion_matrix(patient_df_filtered, lbl_conv_obj)\n",
    "    full_confusion_data[fold] = confusion_data\n",
    "\n",
    "confusion_matrix.get_fold_statistics(full_confusion_data, lbl_conv_obj).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curves\n",
    "Plot ROC curves for sensitivity/specificity and precision/recall for any (combination of) labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_label = ['PML_RARA']   #can also contain a list of multiple labels\n",
    "roc_curve.plot(patient_df, true_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy plots\n",
    "Plot patient entropy (divergence of prediction values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_plot.entropy_vs_myb(patient_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APL misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_df.loc[(patient_df['gt_label'] == 'PML_RARA') & ~(patient_df['pred_lbl'] == 'PML_RARA')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patients: algorithm performance\n",
    "### Define a patient\n",
    "Enter any patient ID to look at the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = 'PKC'\n",
    "bokeh_wrapper.FONTSIZE=16\n",
    "patient_df.loc[patient_id]\n",
    "\n",
    "#'BHS', 'UGU', 'PKC', 'SBY', 'UVT'   JGE->SCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save=os.path.join(fig_export_path, 'barplots', 'prediction_{}.svg'.format(patient_id))\n",
    "prediction_barplot.plot(patient_df.loc[patient_id], reorder=reorder, path_save=path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show random set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_sc_data = sc_df.loc[patient_id]\n",
    "\n",
    "path_save=os.path.join(fig_export_path, 'image_excerpts', 'sample_random_{}.svg'.format(patient_id))\n",
    "image_excerpt.plot(filtered_sc_data[300:336], show_scalebar=True, cols=12, path_save=path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show images ordered by relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = patient_df.loc[patient_id].pred_lbl\n",
    "filtered_sc_data = sc_df.loc[patient_id].copy()\n",
    "filtered_sc_data = filtered_sc_data.sort_values(by=load_data.get_softmax_attention_column(predicted_class), ascending=False)\n",
    "\n",
    "# sample X images in a representative fashion\n",
    "sample_count = 96\n",
    "show_every = len(filtered_sc_data)/sample_count\n",
    "filtered_sc_data['tmp'] = range(len(filtered_sc_data))\n",
    "filtered_sc_data = filtered_sc_data.loc[filtered_sc_data['tmp']%show_every < 1] \n",
    "\n",
    "path_save=os.path.join(fig_export_path, 'image_excerpts', 'sample_sorted_{}.svg'.format(patient_id))\n",
    "image_excerpt.plot(filtered_sc_data[::], show_scalebar=False, cols=12, show_coordinates=True, path_save=path_save)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show swarmplot\n",
    "The presented Swarmplot is interactive and shows cells upon mouseover. Classes of cells can be excluded by clicking the corresponding label in the legend on the right. This cell automatically stores a vector graphic in the folder ```output/swarmplots```, and calculates the distribution of cells in each quartile (see dataframe below interactive figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = patient_df.loc[patient_id].pred_lbl\n",
    "true_class = patient_df.loc[patient_id].gt_label\n",
    "\n",
    "\n",
    "# show_class = 'AML-CBFB-MYH11'\n",
    "show_class = predicted_class\n",
    "\n",
    "filtered_sc_data = sc_df.loc[patient_id]\n",
    "data_with_mappings = image_bytestream.map_images_to_dataframe(filtered_sc_data)\n",
    "data_with_mappings_and_coordinates, xlim, ylim = beeswarm.beeswarm_coordinates(data_with_mappings, \n",
    "                                                                               val_col=load_data.get_softmax_attention_column(show_class))\n",
    "data_with_mappings_and_coordinates['color_values'] = data_with_mappings_and_coordinates['mll_annotation'].fillna('cell')\n",
    "\n",
    "\n",
    "# show interactive plot\n",
    "bokeh_wrapper.multi_swarmplot(data_with_mappings_and_coordinates, \n",
    "          title='Swarmplot for patient {}, prediction: {}, true label: {}'.format(patient_id, predicted_class, true_class), \n",
    "          xlim=xlim, ylim=ylim)\n",
    "\n",
    "# save interactive plot\n",
    "path_save = os.path.join(fig_export_path, 'swarmplots', patient_id +\"_swarmplot_interactive.html\")\n",
    "bokeh_wrapper.multi_swarmplot(data_with_mappings_and_coordinates, \n",
    "          title='Swarmplot for patient {}, prediction: {}, true label: {}'.format(patient_id, predicted_class, true_class), \n",
    "          xlim=xlim, ylim=ylim, path_save=path_save)\n",
    "\n",
    "# define which images should be highlighted for the annotated patients\n",
    "highlight_idx = {\n",
    "    'PKC':[46, 286, 247, 186, 386, 198, 1],\n",
    "    'UGU':[372, 197, 376, 73, 144, 174],\n",
    "    'SBY':[340, 386, 220, 302, 87, 358],\n",
    "    'UVT':[34, 454, 358, 207, 384, 131, 95],\n",
    "    'BHS':[49, 200, 365, 69, 219, 184, 39]\n",
    "}\n",
    "\n",
    "get_highlight = lambda x: None if not x in highlight_idx.keys() else highlight_idx[x]\n",
    "path_save = os.path.join(fig_export_path, 'swarmplots', patient_id +\"_swarmplot.svg\")\n",
    "bokeh_wrapper.export_swarmplot(data_with_mappings_and_coordinates, \n",
    "          title='Swarmplot for patient {}, prediction: {}, true label: {}'.format(patient_id, predicted_class, true_class), \n",
    "          xlim=xlim, ylim=ylim, highlight_idx=get_highlight(patient_id), path_save=path_save, plot_quantiles=load_data.get_softmax_attention_column(predicted_class))\n",
    "\n",
    "# print quantiles and distribution of cells\n",
    "quantiles, borders = bokeh_wrapper.calculate_cells_in_quantiles(data_with_mappings_and_coordinates, \n",
    "                                                       load_data.get_softmax_attention_column(predicted_class), \n",
    "                                                       group_index=True,\n",
    "                                                      sort_by_percentage=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = os.path.join(fig_export_path, 'swarmplots', patient_id +\"_swarmplot_pie.svg\")\n",
    "bokeh_wrapper.plot_piechart(data_with_mappings_and_coordinates, load_data.get_softmax_attention_column(predicted_class), scale_factor=0.3, path_save=path_save, group_pie=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate occlusion and solitary cell predictions as predicted in Fig. 3b\n",
    "occlusion_values = sc_occlusion.calculate_change_on_occlusion(data_with_mappings_and_coordinates, result_folder_path, \n",
    "                                               folders_cv_available, feature_prefix, lbl_conv_obj)\n",
    "\n",
    "bokeh_wrapper.init_sol_plot(occlusion_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP embedding\n",
    "\n",
    "The interactive UMAP figures require quite a lot of RAM and computing power. To calculate the occlusion values, the use of CUDA-capable GPUs is highly recommended and will greatly speed up the process. From here on out, we recommend 32GB of RAM, otherwise the kernel will most likely crash.\n",
    "\n",
    "1. Calculate or load the UMAP embedding (not necessary, if an old gzip file should be loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample cells randomly for embedding\n",
    "fold_filter = 2\n",
    "sc_umap_sample = sc_df.loc[sc_df['fold'] == fold_filter].sample(frac=1, random_state=1).copy()\n",
    "\n",
    "sc_df_umap = umap_embedding.generate_embedding(sc_umap_sample, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load all additional image data and calculate occlusion values. Either save the dataframe, or skip the data preparation process and load an old one. For this, pyarrow is required (https://anaconda.org/conda-forge/pyarrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load=input(\"Load data?    (y/n): \")=='y'\n",
    "save=input(\"Save results? (y/n): \")=='y'\n",
    "\n",
    "recalculate_occlusion=input(\"Recalculate occlusion? (y/n)\")=='y'\n",
    "\n",
    "load_dir = 'suppl_data/dataframe_saves'\n",
    "if not load:\n",
    "    # prepare SC data for umap embedding: add all annotated patients\n",
    "    sc_umap_annotated = sc_df.loc[~sc_df['mll_annotation'].isna() & ~(sc_df['fold'] == fold_filter)]\n",
    "    sc_umap_annotated = umap_embedding.embed_new_data(sc_umap_annotated)\n",
    "    sc_prepared = pd.concat([sc_df_umap, sc_umap_annotated], axis=0)\n",
    "    \n",
    "    # load single cell images\n",
    "#     sc_prepared = image_bytestream.map_images_to_dataframe(sc_prepared)\n",
    "    \n",
    "    # calculate occlusion values\n",
    "    sc_prepared = sc_occlusion.calculate_change_on_occlusion(sc_prepared, result_folder_path, \n",
    "                                               folders_cv_available, feature_prefix, lbl_conv_obj)\n",
    "else:\n",
    "    \n",
    "    print(\"Found data: \")\n",
    "    print(os.listdir(load_dir))\n",
    "    load_name = input(\"Enter dataframe to load: \")\n",
    "    sc_prepared = pd.read_parquet(os.path.join(load_dir, load_name))\n",
    "    \n",
    "if recalculate_occlusion:\n",
    "    sc_prepared = sc_occlusion.calculate_change_on_occlusion(sc_prepared, result_folder_path, \n",
    "                                               folders_cv_available, feature_prefix, lbl_conv_obj)\n",
    "    \n",
    "if save:\n",
    "    save_name = input(\"Save dataframe as: \")\n",
    "    sc_prepared.to_parquet(os.path.join(load_dir, save_name))\n",
    "\n",
    "print(\"Operation complete. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bokeh_wrapper.umap(sc_prepared)\n",
    "path_save = os.path.join(fig_export_path, 'umaps_categorical', \"legend_outline.{}\".format('png'))\n",
    "bokeh_wrapper.export_umap(sc_prepared, data_column='mll_annotation', legend_capt='Annotated cell class', \n",
    "                  highlight=False, zorder_adapt_by_color=True, grayscatter=True, dotsize=35, path_save=path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Occlusion UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occlusion_for_class = 'AML-PML-RARA'\n",
    "bokeh_wrapper.umap(sc_prepared, title=\"Occlusion-UMAP\", data_column=\"occlusion_{}\".format(occlusion_for_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Attention UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_for_class = 'AML-RUNX1-RUNX1T1'\n",
    "bokeh_wrapper.umap(sc_prepared, title=\"UMAP\", legend_header=\"Annotated cell type\", \n",
    "                   data_column=load_data.get_raw_attention_column(attention_for_class), grayscatter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solitary UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solitary_for_class = 'AML-PML-RARA'\n",
    "bokeh_wrapper.umap(sc_prepared, title=\"UMAP\", legend_header=\"Solitary predictions for cell type\", \n",
    "                   data_column=\"solitary_{}\".format(solitary_for_class), grayscatter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sc_prepared_fold_0 = sc_prepared.loc[sc_prepared['fold'] == 0]\n",
    "\n",
    "path_save = os.path.join(fig_export_path, 'umaps_solitary', \"solitary.{}\".format('png'))\n",
    "bokeh_wrapper.export_umap(sc_prepared_fold_0, title='UMAP embedding: single cell MIL predictions', \n",
    "                          data_column=\"s_full_plot\", grayscatter=True, dotsize=3, thresh_sol=0.75, path_save=path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample example images with the highest predictive values\n",
    "\n",
    "show_highest = 'SCD'\n",
    "show_highest_cnt = 8\n",
    "cols = 8\n",
    "\n",
    "sol_cols = [\n",
    "    'solitary_softmax_AML-PML-RARA',\n",
    "    'solitary_softmax_AML-NPM1',\n",
    "    'solitary_softmax_AML-CBFB-MYH11',\n",
    "    'solitary_softmax_AML-RUNX1-RUNX1T1',\n",
    "    'solitary_softmax_SCD'\n",
    "]\n",
    "\n",
    "sc_prepared_fold_0 = sc_prepared.loc[sc_prepared['fold'] == 0]\n",
    "\n",
    "sc_prepared_fold_0['solitary_softmax_idxmax'] = sc_prepared_fold_0[sol_cols].idxmax(axis=1)\n",
    "tmp_frame = sc_prepared_fold_0.loc[sc_prepared_fold_0['solitary_softmax_idxmax'] == 'solitary_softmax_'+show_highest]\n",
    "\n",
    "# quantile_val = tmp_frame['att_raw_'+show_highest].quantile(0.9)\n",
    "# tmp_frame = tmp_frame.loc[tmp_frame['att_raw_'+show_highest] > quantile_val]\n",
    "\n",
    "tmp_frame = tmp_frame.sort_values(by='att_raw_'+show_highest, ascending=False)[:show_highest_cnt]\n",
    "\n",
    "path_save = os.path.join(fig_export_path, 'umaps_solitary', \"solitary_highest_{}.{}\".format(show_highest, 'png'))\n",
    "image_excerpt.plot(tmp_frame, show_scalebar=False, show_coordinates=False, cols=cols, path_save=path_save, show_patient_class=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export all UMAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtype='png'\n",
    "\n",
    "highlight_in_scatter = [\n",
    "    17485,   # atypical promyelocyte\n",
    "    16944,   # myeloblast\n",
    "    16978,   # monocyte\n",
    "    17189,   # NGS\n",
    "    17536,   # normo\n",
    "    17476,   # metamyelocyte\n",
    "    3777,    # NGB\n",
    "    16696,   # EOS\n",
    "    16147,   # smudge\n",
    "    1781,    # lymph\n",
    "    16180,   # LGL\n",
    "]\n",
    "\n",
    "sc_prepared['highlight'] = [False]*len(sc_prepared)\n",
    "sc_prepared.loc[sc_prepared['index'].isin(highlight_in_scatter), 'highlight'] = [True]*len(highlight_in_scatter)\n",
    "\n",
    "path_save = os.path.join(fig_export_path, 'umaps_categorical', \"umap_full_fold.{}\".format('png'))\n",
    "bokeh_wrapper.export_umap(sc_prepared, data_column='mll_annotation', legend_capt='Annotated cell class', \n",
    "                  highlight=True, zorder_adapt_by_color=True, grayscatter=True, dotsize=35, path_save=path_save)\n",
    "\n",
    "sc_prepared['highlight'] = [False]*len(sc_prepared)\n",
    "\n",
    "# categorical umaps for every patient\n",
    "annotated_indices = sc_prepared.loc[~sc_prepared['mll_annotation'].isna()].index.unique()\n",
    "for idx in annotated_indices:\n",
    "    subframe = sc_prepared.copy()\n",
    "    annotations_stash = subframe.loc[idx, 'mll_annotation']\n",
    "    subframe['mll_annotation'] = [None]*len(subframe)\n",
    "    subframe.loc[idx, 'mll_annotation'] = annotations_stash\n",
    "    path_save = os.path.join(fig_export_path, 'umaps_categorical', \"umap_idx_{}.{}\".format(idx, dtype))\n",
    "\n",
    "    bokeh_wrapper.export_umap(subframe, data_column='mll_annotation', legend_capt='Annotated cell class', \n",
    "                    highlight=False, zorder_adapt_by_color=True, grayscatter=True, dotsize=35, path_save=path_save)\n",
    "\n",
    "for class_lbl in list(lbl_conv_obj.df.true_lbl):\n",
    "    \n",
    "    path_save = os.path.join(fig_export_path, 'umaps_occlusion', \"occlusion_{}.{}\".format(class_lbl, dtype))\n",
    "    bokeh_wrapper.export_umap(sc_prepared, data_column=\"occlusion_{}\".format(class_lbl), legend_capt='Annotated cell class', \n",
    "                  highlight=False, zorder_adapt_by_color=False, grayscatter=True, dotsize=10, path_save=path_save)\n",
    "    \n",
    "    path_save = os.path.join(fig_export_path, 'umaps_attention', \"attention_{}.{}\".format(class_lbl, dtype))\n",
    "    bokeh_wrapper.export_umap(sc_prepared, data_column=load_data.get_raw_attention_column(class_lbl), legend_capt='Annotated cell class', \n",
    "                  highlight=False, zorder_adapt_by_color=False, grayscatter=True, dotsize=10, path_save=path_save)\n",
    "    \n",
    "    path_save = os.path.join(fig_export_path, 'umaps_solitary', \"solitary_softmax_{}.{}\".format(class_lbl, dtype))\n",
    "    bokeh_wrapper.export_umap(sc_prepared, data_column=\"solitary_softmax_{}\".format(class_lbl),grayscatter=True, \n",
    "                              dotsize=10, path_save=path_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scemila",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
